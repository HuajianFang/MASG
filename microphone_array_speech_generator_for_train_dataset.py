#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Date     : 2019-11-25 09:33:27
# @Author   : Cheng Rui (chengrui@emails.bjut.edu.cn)
# @Function : microphone array speech generator for train dataset
# @Veision  : Release 0.3

'''
Version Information 

Release 0.1

[1] The generator used for single sentence test, and verifies the accuracy of the data 
set generator.

Release 0.2

[1] The generator is encapsulated as a function, which is executed in the form of call, 
and is convenient for the generation of large-scale microphone array speech data.

[2] Automatic output of microphone array signal generated by circulation.

Release 0.3

[1] Using the encapsulated generator function, the speech data set is read automatically
and circularly, to generate the microphone array speech in room acoustic.
[2] Support simultaneous generation of microphone array signals with four signal-to-noise
ratios (-5dB, 0dB, 5dB, 10dB) and seven reverberation times (200ms, 300ms, 400ms, 500ms, 
600ms, 700ms, 800ms).
'''

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import glob
import pyroomacoustics as pra
import add_noise_for_multichannel as an

# ================== #
#      Function      #
# ================== #

# single source microphone array clean speech generator.
def mic_clean_generator(room_size, target_location, target, fs, microphone_array, amplifier):
    '''
    This function is used to implement single source microphone array clean speech generator.
    
    Usage:  mic_clean_generator(room_size, target_location, target, fs,microphone_array, amplifier)

        room_size                  - the size of room [length, width, high]
        target_location            - the location of target speech [x, y, z]
        target                     - the array of target speech file
        fs                         - sampling frequency
        microphone_array           - the location of microphone array
        amplifier                  - the multiple of microphone's built-in amplifier
    
    Example call:
        clean = mic_clean_generator(room_size, target_location, target, fs, microphone_array, amplifier)

    References:
    mircophone array speech generator release 0.1
    
    Author: Rui Cheng
    '''

    # create the room
    room = pra.ShoeBox(room_size, fs=fs, absorption=1.0, max_order=17)
    '''fig, ax = room.plot()
    ax.set_xlim([0, 4.5])
    ax.set_ylim([0, 6.5])
    ax.set_zlim([0, 4])
    plt.show()
    '''
    # add source
    room.add_source(target_location, signal=target, delay=0)
    #room.add_source([3.5, 3.0, 1.76], signal=interf[:len(target)], delay=0)    # for multi-source
    '''fig, ax = room.plot()
    ax.set_xlim([0, 4.5])
    ax.set_ylim([0, 6.5])
    ax.set_zlim([0, 4])
    plt.show()'''

    # add microphone array
    R = microphone_array
    fft_len = 512
    Lg_t = 0.100
    Lg = np.ceil(Lg_t*room.fs)
    mic_array = pra.Beamformer(R, room.fs, N=fft_len, Lg=Lg)
    room.add_microphone_array(mic_array)
    '''fig, ax = room.plot()
    ax.set_xlim([0, 4.5])
    ax.set_ylim([0, 6.5])
    ax.set_zlim([0, 4])
    plt.show()'''

    # create the room impulse response
    # compute image sources
    room.image_source_model(use_libroom=True)
    # visualize 3D polyhedron room and image sources
    '''fig, ax = room.plot(img_order=3)
    fig.set_size_inches(20, 10)
    plt.show()'''

    '''room.plot_rir()
    fig = plt.gcf()
    fig.set_size_inches(20, 10)
    plt.show()'''

    # microphone speech
    room.simulate()

    # clean speech in each channel
    clean = amplifier*room.mic_array.signals.astype("int16")

    return clean

# single source microphone array reverberation speech generator
def mic_rever_generator(room_size, target_location, target, fs, microphone_array, amplifier, absorption_value):
    '''
    This function is used to implement single source microphone array reverberation speech generator.
    
    Usage:  mic_rever_generator(room_size, target_location, target, fs, microphone_array, amplifier, absorption_value)
               
        room_size                  - the size of room [length, width, high]
        target_location            - the location of target speech [x, y, z]
        target                     - the array of target speech file
        fs                         - sampling frequency
        microphone_array           - the location of microphone array
        amplifier                  - the multiple of microphone's built-in amplifier
        absorption_value           - absorption value of room wall
    
    Example call:
        clean_rever = mic_rever_generator(room_size, target_location, target, fs, microphone_array, amplifier, absorption_value)
    
    References:
    mircophone array speech generator release 0.1
    
    Author: Rui Cheng
    '''

    # create the room
    room = pra.ShoeBox(room_size, fs=fs, absorption=absorption_value, max_order=17)

    room.add_source(target_location, signal=target, delay=0)
    #room.add_source([3.5, 3.0, 1.76], signal=interf[:len(target)], delay=0)

    # add microphone array
    R = microphone_array
    fft_len = 512
    Lg_t = 0.100
    Lg = np.ceil(Lg_t*room.fs)
    mic_array = pra.Beamformer(R, room.fs, N=fft_len, Lg=Lg)
    room.add_microphone_array(mic_array)

    # create the room impulse response
    # compute image sources
    room.image_source_model(use_libroom=True)

    # microphone speech
    room.simulate()

    # clean speech in each channel
    clean_rever = amplifier*room.mic_array.signals.astype("int16")

    # return
    return clean_rever





# ================== #
#        Main        #
# ================== #

print('Train Dataset')
print('\n')
print(
    'Microphone Array Speech Generator in Room Acoustic [Release 0.3]')
print(
    '==================================================================')
print('\n')

# ================== #
#     Parameters     #
# ================== #

print(
    'Parameters')
print(
    '------------------------------------------------------------------')

print('---- Fixed parameter ----')
# room size
room_size = [4, 3, 3]
# microphone array
microphone_array = np.c_[
    [1.82, 1.5, 0.75],  # mic 0
    [1.86, 1.5, 0.75],  # mic 1
    [1.90, 1.5, 0.75],  # mic 2
    [1.94, 1.5, 0.75],  # mic 3
    [1.98, 1.5, 0.75],  # mic 4
    [2.02, 1.5, 0.75],  # mic 5
    [2.06, 1.5, 0.75],  # mic 6
    [2.10, 1.5, 0.75],  # mic 7
    [2.14, 1.5, 0.75],  # mic 8
    [2.18, 1.5, 0.75],  # mic 9
    ]
# microphone amplification
amplifier = 10
print('room_size')
print(room_size)
print('microphone_array')
print(microphone_array)
print('microphone_amplifier')
print(amplifier)

print('---- Variation parameters contained in the dataset ----')
# target sources location
target_location = [
    [0.6, 2.8, 1.3],    # tar 01
    [1.3, 2.8, 1.3],    # tar 02
    [2.0, 2.8, 1.3],    # tar 03
    [2.7, 2.8, 1.3],    # tar 04
    [3.4, 2.8, 1.3],    # tar 05
    [0.2, 2.15, 1.3],   # tar 06
    [1.3, 2.25, 1.3],   # tar 07
    [2.0, 2.25, 1.3],   # tar 08
    [2.7, 2.25, 1.3],   # tar 09
    [0.75, 1.5, 1.3],   # tar 10
    [0.2, 0.85, 1.3],   # tar 11
    [1.3, 0.75, 1.3],   # tar 12
    [2.0, 0.75, 1.3],   # tar 13
    [2.7, 0.75, 1.3],   # tar 14
    [0.6, 0.2, 1.3],    # tar 15
    [1.3, 0.2, 1.3],    # tar 16
    [2.0, 0.2, 1.3],    # tar 17
    [2.7, 0.2, 1.3],    # tar 18
    [3.4, 0.2, 1.3],    # tar 19
    [3.8, 1.5, 1.8],    # tar 20
    ]
# SNR: -5dB, 0dB, 5dB, 10dB
SNR = [-5, 0, 5, 10]
# absorption:
absorption_value = [
    [0.4391, 200],            # alpha=0.4391, RT60=200ms
    [0.2927, 300],            # alpha=0.2927, RT60=300ms
    [0.2195, 400],            # alpha=0.2195, RT60=400ms
    [0.1756, 500],            # alpha=0.1756, RT60=500ms
    [0.1464, 600],            # alpha=0.1464, RT60=600ms
    [0.1255, 700],            # alpha=0.1255, RT60=700ms
    [0.1098, 800],            # alpha=0.1098, RT60=800ms
    ]
print('target_location')
print(target_location)
print('signal_to_noise')
print(SNR)
print('absorption')
print(absorption_value)

# target speech file path
MASG_target_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\target\\'
# noise signal path
noise_file = 'C:\\Projects\\chengrui\\Multi_Data\\Data\\Noisex92\\babble.wav'
# microphone speech file path
MASG_clean_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\mic_clean\\'
MASG_clean_noise_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\mic_clean_noise\\'
MASG_clean_rever_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\mic_clean_rever\\'
MASG_clean_rever_noise_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\mic_clean_rever_noise\\'
MASG_noise_path = 'C:\\Projects\\chengrui\\Multi_Data\\MASG_mic_speech_train\\mic_noise\\'

# read the target speech file
target_file_names = np.array([])
for file in glob.glob(MASG_target_path + '*.wav'):
    target_file_names = np.append(target_file_names, file.strip(MASG_target_path))
print('target_file_names')
print(target_file_names, target_file_names.shape)
print('\t')

print(
    'Generate Microphone Array Speech')
print(
    '------------------------------------------------------------------')

# read noise signal
fs, noise = wavfile.read(noise_file) 

# count index
count = 1

# One by one voice processing
for file_name in target_file_names:

    # read target speech
    fs, target = wavfile.read(MASG_target_path+file_name) 
    
    # ================= #
    #     Generator     #
    # ================= #
    
    for snr_index in range(4):
        for rt_index in range(7):
            # clean
            clean = mic_clean_generator(room_size, target_location[int(file_name[1:3])-1], target, fs, microphone_array, amplifier)
            # reverberation
            clean_rever = mic_rever_generator(room_size, target_location[int(file_name[1:3])-1], target, fs, microphone_array, amplifier, absorption_value[rt_index][0])
            # add noise
            out_clean_rever_noise, out_clean_noise, out_noise = an.addnoise(clean, clean_rever, noise, SNR[snr_index], fs)

            # ===================== #
            #     Wavfile.wirte     #
            # ===================== #

            # write wavfile
            for i in range(microphone_array.shape[1]):
                # file path
                file_path = 'ch'+str(i)+'\\'+str(SNR[snr_index])+'dB\\'+str(int(absorption_value[rt_index][1]))+'ms\\'
                # clean
                wavfile.write(
                    MASG_clean_path+file_path+file_name[:7]+'_ch'+str(i)+'_clean_'+str(SNR[snr_index])+'dB_'+str(int(absorption_value[rt_index][1]))+'ms.wav', fs, clean[i,:])
                # clean_noise
                wavfile.write(
                    MASG_clean_noise_path+file_path+file_name[:7]+'_ch'+str(i)+'_clean_noise_'+str(SNR[snr_index])+'dB_'+str(int(absorption_value[rt_index][1]))+'ms.wav', fs, out_clean_noise[i,:])
                # clean_rever
                wavfile.write(
                    MASG_clean_rever_path+file_path+file_name[:7]+'_ch'+str(i)+'_clean_rever_'+str(SNR[snr_index])+'dB_'+str(int(absorption_value[rt_index][1]))+'ms.wav', fs, clean_rever[i,:])
                # clean_rever_noise
                wavfile.write(
                    MASG_clean_rever_noise_path+file_path+file_name[:7]+'_ch'+str(i)+'_clean_rever_noise_'+str(SNR[snr_index])+'dB_'+str(int(absorption_value[rt_index][1]))+'ms.wav', fs, out_clean_rever_noise[i,:])
                # noise
                wavfile.write(
                    MASG_noise_path+file_path+file_name[:7]+'_ch'+str(i)+'_noise_'+str(SNR[snr_index])+'dB_'+str(int(absorption_value[rt_index][1]))+'ms.wav', fs, out_noise[i,:])

    print(file_name[:7], 'generation completed.', '[', count, '/ 400 ]')
    count = count + 1

print('channel number:', microphone_array.shape[1])
print('Microphone array speech and noise has been generated.')
print('\t')
plt.show()


